{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ytz/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/ytz/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
    "from eli5.sklearn import InvertableHashingVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import mpld3\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueid</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>text length</th>\n",
       "      <th>sentiment_rate</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33780</th>\n",
       "      <td>228941</td>\n",
       "      <td>Tadalafil</td>\n",
       "      <td>Erectile Dysfunction</td>\n",
       "      <td>work well headache side effect</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2016-06-20</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47801</th>\n",
       "      <td>77683</td>\n",
       "      <td>Cephalexin</td>\n",
       "      <td>Bladder Infection</td>\n",
       "      <td>good but take long duration treatment such day...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2009-07-29</td>\n",
       "      <td>63</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32026</th>\n",
       "      <td>156672</td>\n",
       "      <td>Dulaglutide</td>\n",
       "      <td>Diabetes, Type 2</td>\n",
       "      <td>started trulicity one month ago daily blood le...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>6</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47455</th>\n",
       "      <td>146279</td>\n",
       "      <td>Suboxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>have severe chronic pain and have had everythi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2009-07-16</td>\n",
       "      <td>35</td>\n",
       "      <td>417</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27331</th>\n",
       "      <td>231662</td>\n",
       "      <td>Trazodone</td>\n",
       "      <td>ibromyalgia</td>\n",
       "      <td>have been trazodone for over year doctor precr...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>43</td>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44898</th>\n",
       "      <td>155491</td>\n",
       "      <td>Metronidazole</td>\n",
       "      <td>Bacterial Vaginitis</td>\n",
       "      <td>first time had wa giving metronidazole take tw...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2015-03-28</td>\n",
       "      <td>8</td>\n",
       "      <td>422</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27937</th>\n",
       "      <td>216222</td>\n",
       "      <td>Copper</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>got year copper iud and have never given birth...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2015-05-14</td>\n",
       "      <td>8</td>\n",
       "      <td>770</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>101324</td>\n",
       "      <td>Aubra</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>received aubra from planned parenthood and fin...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-12-11</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45589</th>\n",
       "      <td>84998</td>\n",
       "      <td>Ethinyl estradiol / norgestimate</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>there minus only writing review remind myself ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>6</td>\n",
       "      <td>529</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10945</th>\n",
       "      <td>56103</td>\n",
       "      <td>Estradiol</td>\n",
       "      <td>Atrophic Vaginitis</td>\n",
       "      <td>rootsgal they generally say take month have fu...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>45</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uniqueid                          drugName             condition  \\\n",
       "33780    228941                         Tadalafil  Erectile Dysfunction   \n",
       "47801     77683                        Cephalexin     Bladder Infection   \n",
       "32026    156672                       Dulaglutide      Diabetes, Type 2   \n",
       "47455    146279                          Suboxone     Opiate Dependence   \n",
       "27331    231662                         Trazodone           ibromyalgia   \n",
       "...         ...                               ...                   ...   \n",
       "44898    155491                     Metronidazole   Bacterial Vaginitis   \n",
       "27937    216222                            Copper         Birth Control   \n",
       "3758     101324                             Aubra         Birth Control   \n",
       "45589     84998  Ethinyl estradiol / norgestimate         Birth Control   \n",
       "10945     56103                         Estradiol    Atrophic Vaginitis   \n",
       "\n",
       "                                                  review  rating        date  \\\n",
       "33780                    work well headache side effect      9.0  2016-06-20   \n",
       "47801  good but take long duration treatment such day...     9.0  2009-07-29   \n",
       "32026  started trulicity one month ago daily blood le...     8.0  2016-10-18   \n",
       "47455  have severe chronic pain and have had everythi...     2.0  2009-07-16   \n",
       "27331  have been trazodone for over year doctor precr...    10.0  2015-09-17   \n",
       "...                                                  ...     ...         ...   \n",
       "44898  first time had wa giving metronidazole take tw...     8.0  2015-03-28   \n",
       "27937  got year copper iud and have never given birth...     9.0  2015-05-14   \n",
       "3758   received aubra from planned parenthood and fin...     1.0  2016-12-11   \n",
       "45589  there minus only writing review remind myself ...     1.0  2016-01-21   \n",
       "10945  rootsgal they generally say take month have fu...     9.0  2015-04-30   \n",
       "\n",
       "       usefulCount  text length  sentiment_rate  month  year  \n",
       "33780            4           35               1      6  2016  \n",
       "47801           63           73               1      7  2009  \n",
       "32026            6          384               1     10  2016  \n",
       "47455           35          417               0      7  2009  \n",
       "27331           43          570               1      9  2015  \n",
       "...            ...          ...             ...    ...   ...  \n",
       "44898            8          422               1      3  2015  \n",
       "27937            8          770               1      5  2015  \n",
       "3758             1          430               0     12  2016  \n",
       "45589            6          529               0      1  2016  \n",
       "10945           45          118               1      4  2015  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../datasets/df_train_cleaned_shortened.csv')\n",
    "df_train.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugName = df_train['drugName'].tolist()\n",
    "condition = df_train['condition'].tolist()\n",
    "rating = df_train['rating'].tolist()\n",
    "reviews = df_train['review'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in reviews:\n",
    "    allwords_stemmed = tokenize_and_stem(i) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
    "print ('there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.85, max_features=4000,\n",
    "                                 min_df=4, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,2))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(reviews) #fit the vectorizer to synopses\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 5\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "%time km.fit(features)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "#uncomment the below to save your model \n",
    "#since I've already run my model I am loading from the pickle\n",
    "\n",
    "joblib.dump(km,  'doc_cluster.pkl')\n",
    "\n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = {'drugName': drugName, \n",
    "         'condition': condition, \n",
    "         'cluster': clusters, \n",
    "         'rating':rating,\n",
    "        'reviews':reviews}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(drugs, index = [clusters] , columns = ['drugName', 'condition', 'reviews','cluster', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped = frame['rating'].groupby(frame['cluster']) #groupby cluster for aggregation purposes\n",
    "\n",
    "grouped.mean() #average rank (1 to 100) per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "#sort cluster centers by proximity to centroid\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words:\" % i, end='')\n",
    "    \n",
    "    for ind in order_centroids[i, :6]: #replace 6 with n words per cluster\n",
    "        print(' %s' % vocab_frame.iloc[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace\n",
    "    \n",
    "    print(\"Cluster %d condition:\" % i, end='')\n",
    "    for title in frame.iloc[i]['title'].values.tolist():\n",
    "        print(' %s,' % title, end='')\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace\n",
    "    \n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
